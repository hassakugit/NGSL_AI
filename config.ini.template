# --- config.ini.template ---
# Copy this file to config.ini and fill in your values.
# Use standard INI format (sections with [SectionName]).

[Models]
# Hugging Face model ID for the Japanese-to-English translation model
TranslationModelName = Helsinki-NLP/opus-mt-ja-en
# Hugging Face model ID for the Causal Language Model used for vocabulary rewriting
CausalLMModelName = microsoft/Phi-3-mini-128k-instruct
# Set to "true" to trust remote code execution for models (required for some models like Phi-3)
TrustRemoteCode = true

[Credentials]
# Optional: Your Hugging Face Hub access token.
# Required if using gated models or private models. Leave blank if not needed.
# SECURITY NOTE: For production, consider injecting this via Docker environment variables (-e)
# or secrets management instead of placing it directly in config.ini within the image.
HuggingFaceHubToken =

[Processing]
# Preferred device for running models. Options: "auto", "cuda", "mps", "cpu".
# "auto" will attempt CUDA -> MPS -> CPU.
Device = auto
# Maximum number of rewrite attempts in the vocabulary loop
MaxRewriteAttempts = 5

[UI_Defaults]
# Default NGSL week list to select on the frontend
DefaultWeek = 1
# Default vocabulary coverage threshold percentage
DefaultThreshold = 90.0
